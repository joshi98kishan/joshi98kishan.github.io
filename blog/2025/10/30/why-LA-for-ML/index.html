<!doctype html>
<html> <!-- use lang attr in html tag -->

  <head>
    <title>Why linear algebra is important for ML?</title>
    <meta charset="utf-8" />
    <meta name='author' content='Kishan Joshi' />
    <meta
        name="description"
        content="I write blogs on maths and AI." />
    
    <link rel='shortcut icon' href='/assets/images/favicon-16x16.png' />
    
    <!-- for responsive webpage -->
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /> 

    <link rel="stylesheet" href="/assets/css/styles.css" />
    <link rel="stylesheet" href="/assets/css/trac.css" />
    
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js"></script>

    <link type="application/atom+xml" rel="alternate" href="http://localhost:4000/feed.xml" />
    <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Why linear algebra is important for ML?</title>
<meta name="generator" content="Jekyll v4.4.1" />
<meta property="og:title" content="Why linear algebra is important for ML?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="explain how LA came to use in ML and AI. McCulloch-pitts was the first artificial model of biological neuron, and it was linear because that is close to how real neuron works. references: first lecture of CMU DL course https://www.cse.iitm.ac.in/~miteshk/CS7015/Slides/Handout/Lecture2.pdf https://en.wikipedia.org/wiki/Artificial_neuron#Biological_models https://chatgpt.com/share/6903547e-4e64-800e-a631-73a37433dc41 https://en.wikipedia.org/wiki/Neural_circuit#Connections_between_neurons https://en.wikipedia.org/wiki/Synaptic_weight weight in biological neuron." />
<meta property="og:description" content="explain how LA came to use in ML and AI. McCulloch-pitts was the first artificial model of biological neuron, and it was linear because that is close to how real neuron works. references: first lecture of CMU DL course https://www.cse.iitm.ac.in/~miteshk/CS7015/Slides/Handout/Lecture2.pdf https://en.wikipedia.org/wiki/Artificial_neuron#Biological_models https://chatgpt.com/share/6903547e-4e64-800e-a631-73a37433dc41 https://en.wikipedia.org/wiki/Neural_circuit#Connections_between_neurons https://en.wikipedia.org/wiki/Synaptic_weight weight in biological neuron." />
<link rel="canonical" href="http://localhost:4000/blog/2025/10/30/why-LA-for-ML/" />
<meta property="og:url" content="http://localhost:4000/blog/2025/10/30/why-LA-for-ML/" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-30T00:00:00+05:30" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Why linear algebra is important for ML?" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-30T00:00:00+05:30","datePublished":"2025-10-30T00:00:00+05:30","description":"explain how LA came to use in ML and AI. McCulloch-pitts was the first artificial model of biological neuron, and it was linear because that is close to how real neuron works. references: first lecture of CMU DL course https://www.cse.iitm.ac.in/~miteshk/CS7015/Slides/Handout/Lecture2.pdf https://en.wikipedia.org/wiki/Artificial_neuron#Biological_models https://chatgpt.com/share/6903547e-4e64-800e-a631-73a37433dc41 https://en.wikipedia.org/wiki/Neural_circuit#Connections_between_neurons https://en.wikipedia.org/wiki/Synaptic_weight weight in biological neuron.","headline":"Why linear algebra is important for ML?","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/blog/2025/10/30/why-LA-for-ML/"},"url":"http://localhost:4000/blog/2025/10/30/why-LA-for-ML/"}</script>
<!-- End Jekyll SEO tag -->


    <!-- {# % include mathjax.html %} -->
  </head>



  <body>
    <!-- <nav>
    <a href = "/"> Blog </a>
    <a href = "/about"> About </a>
</nav> -->

<div class='nav'>
    <ul class='wrap'>
        <li><a href='/'>Blog</a></li>
        <li><a href='/about'>About</a></li>
        <!-- <li><a href='/feed.xml'>RSS</a></li> -->
    </ul>
</div>    
    <div class='content'>
    <div class='front-matter'>
        <div class='wrap'>
            <h1>Why linear algebra is important for ML?</h1>
            <h4>something</h4>
            <div class='bylines'>
                <div class='byline'>
                    <h3>Published</h3>
                    <p>30 October 2025</p>
                </div>
            </div>

            <!-- Below div is not required. -->
            <!-- <div class='clear'></div> -->
        </div>
    </div>
    <div class='wrap article'>
        <ul>
  <li>explain how LA came to use in ML and AI.</li>
  <li>McCulloch-pitts was the first artificial model of biological neuron, and it was linear because that is close to how real neuron works.
    <ul>
      <li>references:
        <ul>
          <li>first lecture of CMU DL course</li>
          <li>https://www.cse.iitm.ac.in/~miteshk/CS7015/Slides/Handout/Lecture2.pdf</li>
          <li>https://en.wikipedia.org/wiki/Artificial_neuron#Biological_models</li>
          <li>https://chatgpt.com/share/6903547e-4e64-800e-a631-73a37433dc41</li>
          <li>https://en.wikipedia.org/wiki/Neural_circuit#Connections_between_neurons</li>
          <li>https://en.wikipedia.org/wiki/Synaptic_weight
  weight in biological neuron.</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<p>Why linearity?</p>
<ul>
  <li>https://math.stackexchange.com/questions/2871711/what-about-linearity-makes-it-so-useful</li>
</ul>

<p>Two conclusions I came to:</p>
<ul>
  <li>First it is easy to find linear relationship, e.g., least squares or PCA. There is only one solution, you just find that particular solution. That is, there is only one way to establish linear relationship. On the other hand, there are many ways you can find the non-linear relationship.</li>
  <li>Second, it is highly interpretable. You know which variables impact how much to the result.</li>
</ul>

    </div>
    
     <!-- add a logic to only show if there is citation in a post -->
    <div id='bibliography'>
        <div class='wrap'> 
             <!-- <p>References:</p> -->
            <ol class="bibliography"></ol>
        </div>
    </div>

</div>
  </body>
</html>