---
title: Setting The Tone
layout: post
subtitle: About my journey, blogging, importance of maths
---



When I started learning "Machine Learning" in the summer of 2019, I kept learning it since then because I find it very interesting. I learned it using the online resources. And after some couple of months, I got introduced to "Deep Learning" which made me realized that researchers are trying to mimic the human brain, so that computer can do human-level tasks. That idea of giving the human-level intelligence to computers is crazy. Also the idea that one solution can impact the diverse social problems like healthcare, education, agriculture, improving science etc. Since then I kept learning about deep learning, keeping aside the classical ML algorithms. Until now, I worked as ML engineer for 2 years and worked on exciting projects during my job and as a student. 

Mathematics is the language by which we (humans) communicate "How to be intelligent?" to the computer. Intelligence in simpler terms is processing the input (for example, images, text etc.) and based on this input, previous knowledge and the context of the input, take appropriate actions. Computer can only represents the data and knowledge in the form of numbers and can only manupulate the numbers, so that's where the maths equations come into the picture. By the help of human provided maths equations, it can become intelligent i.e. abot to extract the knowledge in the form of numbers (or at least narrow intelligence, i.e. only able to solve a particular problem and not able to solve any arbitrary problem) and then take appropriate actions. Without the mathematical knowledge, how one can communicate the computer ahout how to manipulate numbers to simulate intelligence. Or how a non-mathematician would able to understand that how exactly the scientist has made this AI model intelligent.

But all this time, I was clearly ignoring the mathematics, only relying on whatever mathematics I had learned in my school and first year of undergraduate. I was ignoring it because I was simply lazy to learn it (later I would elaborate why learning maths would make one lazy). And I would try to make my way through my job by just assuming about how already build AI models are working. So only had a half-baked knowledge of existing AI algorithms and surely won't be able to create new AI algorithms or improve the existing ones. Hence, I could not afford to be an AI researcher, the role I aspire for. Because it mainly deals with the questions "How exisiting AI models can be improved in terms of intelligence?" and not "How existing AI models can be implemented to use them at scale?". Implementing the AI system requies one to also work as a software engineer, which I am not interested in. Pushing the boundary of AI, finding new stuff, improve or better unerstand existing algorithms, that's the work I would like to do full time.

Here is the contradiction: **I find the idea of Artificial Intelligence so interesting and want to master it but I am also not trying to master the required mathematics**. I like AI so much that I never think of switching the field or job role. So to resolve this contradiction, I need to make the mathematics part of the contradiction to align with my interest. 

From time to time, I tried to resolve this contradiction by learning mathematics but couldn't learn it properly. After every iteration of me studying mathematics, I would end up with little more knowledge of mathematics but it would not be enough. 

Events (ChatGPT becoming popular) happened such that now I am working full time to resolve the contradiction. My first attempt was to again iterate over the mathematics but this time, in a systematic manner. I went through Linear Algebra, Probability, Statistics and Calculus. After spending the longest time on mathematics, I tried to test my knowledge by trying to understand the current research.

After looking at the open problems, I came to know the limitations of deep learning like robustness, continual learning, high sample complexity, interpretability etc. Since computer vision is my favourite among other subfields of AI, so looking at the potential solutions accordingly, lead me to compositionality and causality. And research of Francesco Locatello, Yoshua Bengio, Bernhard Scholkopf, Geoffrey Hinton and others. Surely I am not good enough _yet_ to properly understand their ongoing research. So, I thought to trace back their research. And find the sequence of key developements which will lead me to the ongoing research. This lead me to Boltzmann Machine (BM)(Hinton et al, 1985) and Hopfield Network (HN)(Hopfield, 1982). BM built upon the ideas of HN and both uses the ideas of Statistical Mechanics. The goal of BM was so ambitious as it tried to solve a broader problem of computer vision - classification, completing the partial image, imagination and understanding the content of the image. In theory, it could do all that but it was slow and not scalable. In 2006, Hinton showed that RBM (a form of BM - Restricted BM) can be used to train "deep" neural network in a better way (before this paper, training deep network was very difficult) and it gave new hope to the deep learning research community. 

The idea of tracing back and finding an older but key paper is good because when understood, it gives better understanding of multiple key developements based on it. Also, since it would be an older paper, so I thought it won't be too hard to understand (less high level concepts and closer to fundamentals). I traced back upto BM. I later came to know that BM is a good starting point, as it is also an important developement in terms of deep learning research. Because of this paper, there was a revival of deep learning in mid 2000's. Fun Fact: In [September 2024](https://github.com/joshi98kishan/deciphering-hopfield-network/blob/1475cb7d8a679f91cf78e58c8570166700383dff/README.md){:target="_blank"}, I decided to study Hopfield Network and Boltzmann Machine  and on [8th october, 2024](https://www.nobelprize.org/prizes/physics/2024/prize-announcement/){:target="_blank"}, Noble Prize in Physics was announced and it was given to the creators of these two models.

To understand BM, I had to understand HN and some simple concepts of Statistical Mechanics (field of Physics). This is for the first time, I took a paper seriously and tried to understand _every_ part of it. Full understanding comes when you see it working, so I implemented them too. This lead me to write three blogs on BM, HN and Statistical Mechanics (Stat Mech). Because as we know, in order to explain something _properly_, one should better know it. So explaining by writing helped my understanding. There were multiple experiments in both the paper (HN and BM) to show the capabilities of each technique. While there were no exact details about how those experiments are implemented, I implemented them based on my understanding. For HN experiments, there was a very slight difference between the results I obtained vs results mentioned in the paper. For BM, I was able to perfectly achieve all (total three) the experiment's results except for the third one. I was inefficient in terms of finding the right set of hyperparameters of the algorithm, it took me a lot of time and I could not spare more time for the third experiment.


[Move these links and corresponding explanations to seperate post]
The blogs are almost in their prefinal versions. Here is the notion link of each blog. And code for HN and BM:
- [Blog-Thermodynamics-Statistical Mechanics-Ising Model-AI](https://www.notion.so/Blog-Thermodynamics-Statistical-Mechanics-Ising-Model-AI-2bfa87ef96fd4cbfba09b493a6250cb2?source=copy_link)
- [Blog - Hopfield Network](https://www.notion.so/Blog-Hopfield-Network-1202f5954fbf80ac9f06fa5929c14493?source=copy_link) ([Code](https://github.com/joshi98kishan/deciphering-hopfield-network))
- [Blog - Boltzmann Machine](https://www.notion.so/Blog-Boltzmann-Machine-1202f5954fbf808ea6d8de1cfee7b30b?source=copy_link) ([Code](https://github.com/joshi98kishan/boltzmann-machine))

All these blogs are little messy and are 90% complete. You would find the grey colored text redundant. Unique selling point of these blogs is that I tried to make them self-contained. And there is complete, clean derivations of required equations in HN and BM.
I haven't completed them because it took me a lot of time reproducing the results. Since the writing part and experiments were almost done (except the last one), and I was not sure how much time the last experiment would take, so I felt like moving to the next key developement - RBM. 

While working on RBM, it occurred to me that I am very inefficient in terms of understanding the paper (taking long time to properly understand them). So, it would take me longer time to reach to current research. And that's my latest, strongest motivation for learning the maths. Why strongest? Because I had just spent 2 full months learning the maths and still I am inefficient to understand the papers.

 
After spending some time thinking about it. I just started to understand how should I understand the maths. I should understand the maths not just from the level of equations but I have to go more deeper until I break the maths concept into basic operations of plus, minus, multiply and divide. 

Learning maths is difficult because there so many layers of abstractions. Until you  







How I would learn any complex subjects like deep (machine??) learning and maths?
I would learn about any method from deep (machine??) learning and high level maths as a tool. I would just learn how that method can be used in the scenarios I am aware of or and not learn it comprehensively (knowing the full power and limitations of it). Let me provide two concrete examples of me learning about MCMC (Maths) and Batch Normalization (Deep Learning). I learned MCMC because it was getting used in Boltzmann Machine and Hopfield Network papers. I learned MCMC just upto an level so that I can understand both the papers. After understanding these two papers, I jumped to the next paper - Restricted Boltzmann Machine (RBM). In RBM, MCMC was being used in a way I though was not possible.
It was used in a parallel way while based on my understanding it could only be used in a sequential manner. So clearly I didn't understood it completely. I had only understood it as a tool for those two papers, where it could be only used as in sequential form. At first, it really surprised me but when I again tried to understand the MCMC in a more detailed manner, then I could understand its parallel use in RBM. So I was only learning MCMC as a tool for the selected papers. I am sure that there is so much more capabilities of MCMC, I am yet to discover.

Another example is Batch Normalization. When I learned about Batch Normalization, I understood that why it was proposed and how it can be useful. It was proposed to make the training of neural networks stable and faster. It seemed that it would become a standard layer in a neural network and that I should use it everytime I build a neural network. But later I came to know that there are some disadvantages and it is not a standard layer. Which is quite the opposite of my understanding. That is the problem with tool based understanding, one understand how a method is useful for a particular scenario. There is no comprehensive understanding which would include all the limitations and advantages of that method. 

I would only have an tool based understanding because of weak maths fundamentals. And tool based understanding is not transferable (or not scalable). If you understand one method, it does not make you better at understanding the other methods. 

But if you have a strong maths fundamentals. Then not only it allows you to have a comprehensive understanding of a particular method but allows you to have a comprehensive understanding of any method. It is that powerful. Also comprehensive understanding of methods also makes the general skill of problem solving better. Because comprehensive understanding would make one learn, how to identify a problem and how different fundamental concepts can be used to create a method. It would help one to create new methods or improve the existing ones. It would make one a good researcher. 

Also, one is tend to forget the tool based understanding because it is based on shaky foundation. After some time, when one tries to recall the understanding, he has to recall the source or paper from which he understood it. How knowledge, experiments and observations of the method is presented in the paper will only help to recall the understanding. So, for every methods, you have to recall their respective sources, which does not sound easy. A good memory is required.  

With comprehensive understanding (with the help of strong maths fundamentals), you would not forget any method easily - be that method from deep (machine??) learning or from high level maths. At some later time, even if you do not remember the source from which you understood it, you can try to re-create the method on the fly. Recreation requires just mixing the maths fundamentals in a right manner and a problem solving skill. If one vaguely remembers the source, then it would also help. Ability to not forget easily, only makes one a better researcher. He can bring together concepts from already learned methods easily to create a new one or improve existing ones. 


So with strong maths fundamentals, one can become powerful?? where you can have comprehensive understanding of any method, ability to improve any method, to create new ones and to recall easily the already understood ones. You become a powerful researcher. And as you keep on comprehensively understand the existing methods, your research or problem solving skill only improves. And you only become powerful??, unlike in tool-based understanding where understanding a method is a burden because you have to remember the source.


All this depends on strong maths fundamentals. Learning maths fundamentals properly is not easy, in the following section, I elaborate on this. But if you have mastered the maths fundamentals, then you won't forget it easily. It is like one time investment, and in return, you remain powerful?? (in the sense explained above) forever and getting even more powerful?? as you move ahead in your research (ofcourse subject to the good functioning of bodily hardware). One time investment means with time, if exact details gets blurred out, you never have to spend same amount of time, you spent while mastering the fundamentals. A **quick revision** will make you the master again. Before futher explanation, let me clear what I meant by "maths fundamentals": maths knowledge, one requires to "easily" understand a high level maths or deep (machine??) learning method. For machine learning, maths fundamentals are Linear Algebra, Probability, Statistics, Multivariate Calculus and sometimes including other maths concepts. In school, we just get introduced to these topics along with other basic topics and learn them in detail in the college. But school level maths is fundamental for ML maths fundamentals. But everyone will agree that school level maths is indeed a one time investment that is a quick revision (in case of exact details blurring out) will make you master again. It is too hard to completely become noob at school level maths. Why? I think because a good study of school level maths wake up the **creator** which is within ourselves. When we think of school level maths, we feel like we could have also created that knowledge, if we were faced with challenges. When we do quick revision, you recall it naturally, as if we are creating the knowledge on the fly, filling up all the gap which got blurred out with time. One reason, we feel like creator because school level maths is so easy that **common sense** starts to work (for now, common sense I think is a good explanation until a better explanation I come to know). After becoming the creator of school level maths, mastering ML maths fundamentals is also a one time investment. When you master ML maths fundamentals, you realize that the gap between school level maths and ML maths fundamentals is also a common sense. And common sense always remain with you. So whenever details of ML maths fundamentals gets blurred out, with quick revision, your common sense will start to work and you will be able to quickly make the blurred out details crisp again.


After my many iterations of going over maths and reading the papers, I have at least began to understand what is even meant by being a great researcher.
I have an analogy that works perfectly (acc. to my current understanding): The one with strong maths fundamentals?? is like an [production line](https://en.wikipedia.org/wiki/Production_line) expert, who has the knowledge of every production machine any production line (be it for potato chips, tyres, pencil etc.) can have. A production machine is a machine which does a **particular simple job** like cooling, mixing, boiling, cutting, steaming, shaping, fermentation, centrifugation, printing, packing etc. one can imagine a factory would have. A production line expert **knows in-and-out** how a particular production line is working. Which raw materials it can accept and what products it can produce. How each production machine is converting the input. Knows how material is getting transformed through out the production line. He knows how to **modify** the production line, if some different raw materials are also need to be accepted. Or can **improve it**, making it more efficient. He can even **create a new** production line for a different product from scratch. 

You might have already understood via the analogy. Here is the further clarification, just in case. The one with strong maths fundamentals?? is compared to the production line expert. Production machine is compared to simple, easy to understand, basic maths operations like plus, multiply etc. This operations are so simple, that they run in your blood already. A production line is compared to any high level maths or deep (machine??) learning method. Raw materials are compared to the input to these methods. And product produced by production line is the output of the method.

With strong maths fundamentals, one should be able to break *any* high level maths or deep (machine??) learning method into *simple operations* like plus, multiply etc. When the method is at work, you should know how an input is changed by every simple operations inside the method, how it is getting transformed into an output, as it runs through a sequence of simple operations forming a method. Like production line expert, it also allows you to modify any method for different scenario (different input) or allows you to improve any method or create a new method from scratch by combining simple operations. Hence, it allows you to become a researcher, a good researcher.


I have two more analogies but they are not as perfect as the production line. But they indeed tell you what it feels like having a strong maths fundamentals, if not then just ignore this para. First one: Being good at maths is like when waters flows through a straight pipe, you would know how every molecule might be flowing in a streamlined motion (or laminar flow) and you have no doubt that it might be moving otherwise. I feel like a a number inside the complex input like vector, is like a water molecule. One with good maths fundamentals should know how it is flowing inside the method. Second one: It is like those inspirational, redemption movies (based on art, sports etc), where a character transforms himself/herself from nothing in different environments as the movie progresses and come out as a winner at the end of a movie. A complex method have the same spirit, transforming the input at every step inside the method and outputting the transformed input. As one can easily understand such movies, in the same way one should understand any high level maths. 


---------

Why I could not learn the maths then?
It requires the ability to concentrate for long enough and hard work. I could not concentrate for longer. To put it simply, to concentrate is difficult because there is only one way to succeed while there are thousand ways to fail. There are thousand ways your mind can wander away while you are trying to concentrate on one topic. With concentration, one works efficiently and achieves the "top speed". Learning maths properly with your top speed would still take some significant amount of time but it will surely be fun in this way. just like when one enjoys driving at high speed and when you tap into the flow state (https://youtube.com/shorts/2zaeRz918Vs?si=ELfFPXOE2MJBv-DR). So when one is young, he could also naturally concentrate and also have enough time. Learning maths properly without your top speed, one would simply give up by observing the rate at which one is moving and distance left to covered. Speed is less, so time required would be more. There is also a factor of quality. One will have the understanding of high quality when one learns with concentration (won't hear the ticking clock, goes to a timeless zone). On the other hand, one is more susceptible (because clock is ticking) to take shortcuts in understanding when learning with lack of concentration (not to say that quality understanding can not be achieved, it's just that it will take a lot of time).

So, to resolve the contradiction, I need to learn maths but it is inherently slow. To learn it at a best speed, I need to develope concentration. Concentration can be developed with practice and discipline. But until you develop the concentration and also maintaining the quality understanding, learning process is slow and boring. I don't wanna compromise the quality of my understanding. Then thoughts starts to arise about when I would be useful and be ready for service.

Answer to this is "Blogging". It solves both the problems - quality learning and service. If you are sharing some information, then it is better for oneself and others, that shared information is best to ones capacity. One would feel like doing a service, because there would at least be few persons in the world, you would love the content and would get benefitted.



Further Topics:
- Our true self is peaceful and blissful. That is, we are at this moment peaceful and blissful.And it will take some time (not years) to "regain" "realize"
- Along with strong maths fundamentals, there is other equally important skill which is required for a research -  is the ability make the "maths work inside the computer". Whatever maths we know, we know it so that we can make the computer intelligent. On paper, doing maths is easy (subject to strong maths fundamentals) but to make it work on computer requires different skills. Making it work on computer comes with "different" set of challenges which can not be solved by just having strong maths fundamentals. Challenges are like this. On paper, you can assume a variable as real and can solve it perfectly because there is no lose of precision. But on computer, a real number is stored only upto a finite precision and not infinite. Or I should better put it, challenge is to do continuous mathematics with discrete numbers. Field of Numerical Linear Algebra is one example of the field that deals with this problem. Other challenge includes the time. When we do maths on paper, we have the power to find that to what value a given sequence will converge to, by taking the limit. 
  There are some computations which we need, which is time taking on paper but fast for computers. To do such computations on computer, we should be able to "completely track the computations". We should know whether computer could do that computation in a more better way or not. Or computed values is the best ones or not. Two examples of such computations are sampling from high dimensional probability distributions and optimization of deep learning models.

- Having state the importance of mathematics and blogging. You have already guessed that I will be writing blogs on mathematics. I will start by Linear Algebra. Earlier, I would say that I wanna master AI. **But now my sole focus is to master Linear Algebra for Machine Learning**. After mastering LA for ML, I will start with mastering Probability and Statistics, Optimization etc. I haven't joined the university to become a good researcher because for joining a good one, you should first able to prove that you can handle the hard curriculam. I have not proved yet to myself, so how can I provide the proof to the university. Putting this out in public, makes me feel like I am enrolling to an university where you have to follow a curriculum and dropping out of it won't be easy and would take some strength. Also, this blog will be useful to others who are facing the same contradiction.

- AI is maths + data.

- **My high level goal is to develope concentration and to understand any difficult topic easily.** 
